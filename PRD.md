# **Product Requirements Document (PRD)**

## **Music Emotion Annotation Tool - Forschungsprojekt & App-Entwicklung**

---

## **1. Ziel und Kontext**

### **Projektvision**

Das Music Emotion Annotation Tool ist ein Forschungsprojekt, das KI beibringt, subjektive Gef√ºhle in Musik zu erkennen und zu visualisieren. Das ultimative Ziel ist es, neurodivergenter Kinder dabei zu helfen, ihre intensiven emotionalen Reaktionen auf Musik zu verstehen und zu regulieren.

### **Duale Zielsetzung**

- **Forschungsziel**: Entwicklung einer KI, die subjektive emotionale Reaktionen auf Musik lernt
- **App-Entwicklung**: Erstellung einer benutzerfreundlichen, performanten Webanwendung
- **Therapeutisches Potenzial**: Grundlage f√ºr assistive Technologien bei neurodivergenter Kinder

### **Zielnutzer**

- **Prim√§r**: Forscher im Bereich Music Emotion Recognition (MER) und Neurodiversit√§t
- **Sekund√§r**: Therapeuten und P√§dagogen, die mit neurodivergenter Kinder arbeiten
- **Terti√§r**: Entwickler von assistiven Technologien und Musik-Apps

---

## **2. Problemstellung**

### **Kernproblem**

Neurodivergente Kinder erleben Gef√ºhle oft intensiver, k√∂nnen sie aber schlechter einordnen, benennen und regulieren. Musik l√∂st bei ihnen starke emotionale Reaktionen aus, die sie √ºberw√§ltigen k√∂nnen. Gleichzeitig fehlen benutzerfreundliche Tools f√ºr die systematische Erforschung dieser Zusammenh√§nge.

### **Warum ist das wichtig?**

- **Emotionale Regulation**: 70% der neurodivergenter Kinder haben Schwierigkeiten mit Gef√ºhlsregulation
- **Musik als Br√ºcke**: Musik ist ein universeller emotionaler Kanal
- **Visuelle Unterst√ºtzung**: Konkrete Visualisierungen helfen bei der Gef√ºhlserkennung
- **Therapeutischer Nutzen**: Grundlage f√ºr neue Behandlungsans√§tze
- **Forschungseffizienz**: Aktuelle Tools sind ineffizient und nicht benutzerfreundlich

---

## **3. Ziele & Erfolgskriterien**

### **Forschungsziele**

1. **KI-Lernen**: Die KI lernt subjektive emotionale Muster aus individuellen Annotationen
2. **Visualisierungsqualit√§t**: Gef√ºhle werden so dargestellt, dass Kinder sie verstehen k√∂nnen
3. **Personalisierung**: Jedes Kind bekommt ein auf seine Wahrnehmung abgestimmtes Modell
4. **Wissenschaftliche Validierung**: Publikationsreife Ergebnisse in MER-Forschung

### **App-Entwicklungsziele**

1. **Benutzerfreundlichkeit**: Intuitive Bedienung f√ºr Forscher und Therapeuten
2. **Performance**: Schnelle Verarbeitung gro√üer Audiodateien
3. **Skalierbarkeit**: Unterst√ºtzung f√ºr umfangreiche Forschungsstudien
4. **Code-Qualit√§t**: Wartbarer, modularer Code f√ºr zuk√ºnftige Erweiterungen

### **Erfolgskriterien**

- **KI-Genauigkeit**: 85% √úbereinstimmung zwischen KI-Vorhersage und tats√§chlichen Gef√ºhlen
- **Visualisierungsverst√§ndnis**: 90% der Kinder k√∂nnen ihre Gef√ºhle korrekt zuordnen
- **App-Performance**: Ladezeit < 3s, Audio-Dekodierung < 5s ‚úÖ
- **Code-Qualit√§t**: 25% Code-Reduktion, modulare Architektur ‚úÖ
- **Forschungsoutput**: Mindestens 2 wissenschaftliche Publikationen
- **Timeline-Performance**: 60fps bei 1000+ Markern ‚úÖ
- **Audio-Features**: 5+ Audio-Feature-Tracks implementiert ‚úÖ

---

## **4. Funktionale Anforderungen**

### **Core Features (MVP) ‚úÖ ABGESCHLOSSEN**

```
US-001: Als Forscher m√∂chte ich Audiodateien laden k√∂nnen ‚úÖ
- Akzeptiert MP3, WAV, FLAC (bis 100MB)
- Automatische Metadaten-Extraktion
- Wellenform-Visualisierung
- Audio-Caching (IndexedDB)

US-002: Als Nutzer m√∂chte ich KI-gest√ºtzte Emotionsanalyse ‚úÖ
- Google Gemini Integration
- Automatische Hotspot-Erkennung
- Kontextuelle Vorschl√§ge (GEMS-Kategorien)
- AI-Fehlerbehandlung & Marker-Erhaltung

US-003: Als Nutzer m√∂chte ich manuelle Marker erstellen ‚úÖ
- Tastatur-Shortcuts (M-Taste)
- Drag & Drop Timeline-Interaktion
- Valence/Arousal/Intensity-Slider
- Emoji-basierte Marker mit emotionaler Kontextualisierung

US-004: Als Nutzer m√∂chte ich Profile verwalten ‚úÖ
- Multi-User-Support
- Personalisiertes KI-Training
- TensorFlow.js-Integration
```

### **Forschungs-Features (Phase 2) üîÑ LAUFEND - 85% ABGESCHLOSSEN**

```
US-005: Als Forscher m√∂chte ich subjektive emotionale Annotationen sammeln ‚úÖ
- Individuelle Valence/Arousal-Bewertungen
- GEMS-Kategorien f√ºr spezifische Emotionen
- Freitext-Beschreibungen emotionaler Reaktionen
- Emoji-basierte Marker mit emotionaler Kontextualisierung

US-006: Als Forscher m√∂chte ich KI-Modelle personalisieren ‚úÖ
- TensorFlow.js-Integration f√ºr lokales Training
- Individuelle Profile f√ºr verschiedene Wahrnehmungsmuster
- Transfer-Learning zwischen √§hnlichen Profilen

US-007: Als Forscher m√∂chte ich emotionale Visualisierungen erstellen ‚úÖ
- Farbkodierte Timeline-Ansichten (GEMS-Farben)
- Emotionale "Hotspots" identifizieren
- Kindgerechte Darstellung von Gef√ºhlen (Emoji-Marker)
- Mehrspurige Timeline mit 5 Audio-Feature-Tracks

US-008: Als Forscher m√∂chte ich Daten f√ºr Studien exportieren ‚úÖ
- Anonymisierte Forschungsdaten
- Statistische Analysen
- Vergleich zwischen neurotypischen und neurodivergenten Mustern
```

### **Advanced Features (Phase 3) üìã GEPLANT**

```
US-009: Als Nutzer m√∂chte ich Genius-Integration
- Song-Metadaten-Suche
- Lyrics-Integration
- Community-Anmerkungen

US-010: Als Nutzer m√∂chte ich erweiterte Visualisierungen ‚úÖ (Teilweise implementiert)
- Mehrspurige Timeline ‚úÖ (5 Tracks implementiert)
- Tooltip-Erweiterungen ‚úÖ (T-003.1 abgeschlossen)
- Struktur-Overlays üìã (Segmentierung-Erkennung geplant)

US-011: Als Therapeut m√∂chte ich kindgerechte Visualisierungen ‚úÖ (Teilweise implementiert)
- Einfache Farb- und Formsprache ‚úÖ (GEMS-Farben, Emoji-Marker)
- Emotionale "Hotspots" identifizieren ‚úÖ
- Interaktive Gef√ºhls-Exploration ‚úÖ (Timeline-Interaktion)
```

---

## **5. Nicht funktionale Anforderungen**

### **Forschungsqualit√§t**

- **Datenintegrit√§t**: Vollst√§ndige Audit-Trails f√ºr alle Annotationen
- **Reproduzierbarkeit**: Alle Experimente sind vollst√§ndig dokumentiert
- **Ethik**: DSGVO-konforme, anonymisierte Datenspeicherung
- **Validierung**: Peer-Review der Forschungsmethoden

### **App-Performance**

- **Ladezeit**: < 3 Sekunden f√ºr 10MB Audio
- **Responsivit√§t**: < 100ms f√ºr UI-Interaktionen
- **Skalierung**: Unterst√ºtzt bis zu 1000 Marker pro Song
- **Bundle-Gr√∂√üe**: Optimierte Chunks f√ºr bessere Performance

### **Code-Qualit√§t**

- **Architektur**: Modulare, wartbare Struktur
- **TypeScript**: Strict Mode, vollst√§ndige Typisierung
- **Testing**: Unit-Tests f√ºr kritische Funktionen
- **Dokumentation**: Umfassende Entwickler-Dokumentation

### **Usability**

- **Lernkurve**: Neue Nutzer k√∂nnen in < 10 Minuten annotieren
- **Accessibility**: WCAG 2.1 AA Compliance
- **Responsive Design**: Funktioniert auf Desktop, Tablet, Mobile

---

## **6. Abgrenzung (Out-of-Scope)**

### **Was wird NICHT abgedeilt:**

- **Klinische Anwendungen**: Keine medizinische Diagnose oder Behandlung
- **Kinder-Direktnutzung**: Fokus liegt auf Forschung, nicht auf Endnutzern
- **Kommerzialisierung**: Keine Produktentwicklung f√ºr den Markt
- **Therapie-Apps**: Keine vollst√§ndigen therapeutischen Systeme
- **Cloud-Services**: Alle Daten bleiben lokal f√ºr Datenschutz
- **Mobile Apps**: Nur Web-basiert f√ºr Plattformunabh√§ngigkeit

---

## **7. Abh√§ngigkeiten & Risiken**

### **Forschungsabh√§ngigkeiten**

- **Ethik-Kommission**: Genehmigung f√ºr Studien mit Kindern
- **Datenschutz**: DSGVO-Compliance f√ºr sensible Daten
- **Fachkr√§fte**: Kooperation mit Therapeuten und P√§dagogen
- **Studienteilnehmer**: Rekrutierung neurodivergenter Kinder

### **Technische Abh√§ngigkeiten**

- **Google Gemini API**: Kosten und Rate-Limits
- **Genius API**: CORS-Probleme, externe Verf√ºgbarkeit
- **TensorFlow.js**: Browser-Kompatibilit√§t
- **Web Audio API**: Browser-Support

### **Risiken & Mitigation**

| Risiko                     | Wahrscheinlichkeit | Auswirkung | Mitigation                          |
| -------------------------- | ------------------ | ---------- | ----------------------------------- |
| Datenschutz-Verst√∂√üe       | Hoch               | Kritisch   | Lokale Verarbeitung, Anonymisierung |
| KI-Bias                    | Mittel             | Hoch       | Diverse Trainingsdaten, Bias-Tests  |
| Therapeutische Wirksamkeit | Hoch               | Kritisch   | Pilotstudien, Expert-Reviews        |
| Forschungsvalidit√§t        | Mittel             | Hoch       | Peer-Review, Methoden-Validierung   |
| Gemini API-Kosten          | Hoch               | Mittel     | Kosten-Monitoring, Fallback-Modi    |
| Browser-Kompatibilit√§t     | Mittel             | Hoch       | Progressive Enhancement, Polyfills  |

---

## **8. Release-Plan & Meilensteine**

### **Phase 1: MVP & Grundlagen (Q1 2024) ‚úÖ ABGESCHLOSSEN**

- ‚úÖ Core Audio-Funktionalit√§t
- ‚úÖ Basis-UI mit Tailwind/shadcn
- ‚úÖ KI-Integration (Gemini)
- ‚úÖ Marker-Erstellung
- ‚úÖ Code-Konsolidierung (25% Reduktion)
- ‚úÖ Bundle-Optimierung

### **Phase 2: Forschungsvalidierung & App-Verbesserung (Q4 2024) üîÑ LAUFEND - 85% ABGESCHLOSSEN**

- ‚úÖ Mehrspurige Timeline (5 Tracks implementiert)
- ‚úÖ Emotionale Hotspot-Visualisierung (GEMS-Farben, Emoji-Marker, Tooltips)
- ‚úÖ Erweiterte Audio-Features (Vocal-Presence, Onset-Detection, Harmonic-Complexity)
- ‚úÖ Audio-Caching (IndexedDB-basiert)
- ‚úÖ AI-Fehlerbehandlung & Marker-Erhaltung
- üîÑ Tooltip-Erweiterungen (T-003.1 abgeschlossen, T-003.2 in Bearbeitung)
- üìã Performance-Optimierung (Lazy Loading, Web Workers)
- üìã Responsive Design (Touch-Gesten, Mobile-Optimierung)

### **Phase 3: Advanced Features & Therapeutische Anwendung (Q1 2025) üìã GEPLANT**

- üìã Genius-Integration
- üìã Erweiterte KI-Features
- üìã Kindgerechte UI-Designs
- üìã Therapeuten-Dashboard
- üìã Fortschritts-Tracking
- üìã Ethik-Kommission-Antrag

### **Phase 4: Forschungsabschluss & Produktionsreife (Q2 2025) üìã GEPLANT**

- üìã Vollst√§ndige Studien
- üìã Wissenschaftliche Publikationen
- üìã Therapeutische Validierung
- üìã Performance-Tuning
- üìã Security-Audit
- üìã Forschungsbericht

---

## **9. Zusammenfassung**

Das Music Emotion Annotation Tool ist ein Forschungsprojekt, das KI beibringt, subjektive Gef√ºhle in Musik zu erkennen. Das ultimative Ziel ist es, neurodivergenter Kinder dabei zu helfen, ihre intensiven emotionalen Reaktionen zu verstehen und zu regulieren.

**Forschungsfokus:**

- üß† **KI-Lernen** subjektiver emotionaler Muster
- üé® **Visualisierung** von Gef√ºhlen f√ºr Kinder
- üë§ **Personalisierung** f√ºr individuelle Wahrnehmung
- üî¨ **Wissenschaftliche Validierung** der Methoden

**App-Entwicklung:**

- üöÄ **Performance**: Schnelle, responsive Benutzeroberfl√§che
- üèóÔ∏è **Architektur**: Modulare, wartbare Codebasis
- üì± **Usability**: Intuitive Bedienung f√ºr Forscher
- üîß **Code-Qualit√§t**: 25% Reduktion, optimierte Bundles

**Therapeutisches Potenzial:**

- Unterst√ºtzung bei Gef√ºhlsregulation
- Musik als therapeutisches Medium
- Grundlage f√ºr neue Behandlungsans√§tze
- Empowerment neurodivergenter Kinder

---

## **üîß Iterative Verbesserungsvorschl√§ge**

### **1. Forschungsvalidierung**

- **Pilotstudien** mit kleinen Gruppen neurodivergenter Kinder
- **Expert-Reviews** von Therapeuten und P√§dagogen
- **Methoden-Validierung** durch Peer-Review

### **2. App-Entwicklung**

- **Performance-Monitoring** mit echten Nutzern
- **Code-Reviews** f√ºr Qualit√§tssicherung
- **Bundle-Analyse** f√ºr weitere Optimierungen

### **3. Therapeutische Integration**

- **Kooperationen** mit Therapiezentren
- **Ethik-Antr√§ge** f√ºr Studien mit Kindern
- **Eltern-Feedback** zu Visualisierungen

### **4. Wissenschaftliche Qualit√§t**

- **Publikationen** in MER- und Neurodiversit√§ts-Journalen
- **Konferenzbeitr√§ge** f√ºr internationale Sichtbarkeit
- **Open Science** f√ºr Reproduzierbarkeit

### **5. Langzeitentwicklung**

- **Langzeitstudien** zur therapeutischen Wirksamkeit
- **Vergleichsstudien** zwischen verschiedenen Gruppen
- **Technologie-Transfer** zu therapeutischen Anwendungen

**N√§chster Schritt**: T-003.2 (Erweiterte KI-Analyse mit musikalischem Kontext) implementieren, um die Tooltip-Erweiterungen abzuschlie√üen. Anschlie√üend Fokus auf Performance-Optimierung (Lazy Loading, Web Workers) und Responsive Design (Touch-Gesten, Mobile-Optimierung).
